230321 P3 数学基础
# 1 线性代数

<details>
<summary>数学基础</summary>

## 1.1 向量
向量长度
若a为标量，。。。

向量点积，正交

## 1.2矩阵

范数
主要用F范数，元素平方和再开根号

特殊矩阵
矩阵反对称
正定矩阵
正交矩阵
置换矩阵

特征向量

<details>
<summary>其他</summary>

矩阵乘法
矩阵对称

</details>


</details>

<details>
<summary>代码实现</summary>

创建矩阵
矩阵转置

高维度张量->可拆解为多个低纬度张量进行解释

矩阵按元素乘法：哈达玛积
`A*B`

按张量维度求和（这些维度计算完成后消失，可用于降维）
对于`A.shape=[2,5,4]`
`A.sum(axis=0)`沿第一个维度求和，剩下`A.shape=[5,4]`
`A.sum(axis=[0,1])`对第一，第二个维度求和，剩下`A.shape=[4]`
`sum_A=A.sum(axis=1,keepdim=True)`求和时保留原张量维度

`A.cumsum(axis=0)`累加求和（前缀和）

点积
`torch.dot(x,y)`（仅一维向量）
`torch.sum(X,Y)`
`torch.mv(A,x)`矩阵乘向量
`torch.mm(A,B)`矩阵乘积

范数
`torch.norm(v)`向量的$L_2$范数
`torch.abs(v).sum()`或`torch.norm(v,1)`向量的$L_1$范数
`torch.norm(A)`矩阵的F范数
<details>
<summary>其他</summary>

`.clone`深拷贝
`A.sum()`张量元素和
`A.mean()`
</details>

</details>


# 2 *#矩阵运算
标量导数
亚导数：对不可微的点
*#梯度：向量导数
（需要去了解分子布局与分母布局？）
- 分子布局
- 向量关于向量的导数

矩阵导数

Pytorch有自动微分，好耶！

# 3 #自动求导

<details>
<summary>数学基础</summary>

#向量链式法则
计算图
#自动求导的两种模式
- 正向累积
- 反向累积

</details>

<details>
<summary>代码实现</summary>

准备
```
x = torch.arange(4.0)
x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)
x.grad  # 此处于存放梯度 默认值是None
y = 2 * torch.dot(x, x) #是一个标量
```
通过调用反向传播函数来自动计算`y`关于`x`每个分量的梯度
```
y.backward()
```
在默认情况下，PyTorch会累积梯度，我们需要清除之前的值
```
x.grad.zero_()
```

？？
#非标量变量的反向传播
#将部分计算分离到计算图之外-锁定参数
#Python控制流的梯度计算
</details>
